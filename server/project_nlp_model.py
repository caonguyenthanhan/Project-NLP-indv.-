# -*- coding: utf-8 -*-
import sys
import io

# Buộc stdout và stderr sử dụng UTF-8
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

"""project_nlp_modele.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q3WmzoLTQc6dSEmsBGwODxTHCpF8wsih
"""

import pandas as pd
import numpy as np
import joblib
from datasets import load_dataset
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import os

# Hàm tải dataset từ Hugging Face
def load_dataset_from_hf(dataset_name, split='train'):
    dataset = load_dataset(dataset_name, split=split, trust_remote_code=True)
    return pd.DataFrame(dataset)

# Hàm hỗ trợ
def preprocess_and_train(data, text_column, label_column, task_name):
    label_counts = data[label_column].value_counts()
    if len(label_counts) < 2:
        print(f"Cảnh báo: Dữ liệu '{task_name}' chỉ chứa một lớp, cần kiểm tra lại!")
        return {}, None, {}

    X_train, X_test, y_train, y_test = train_test_split(
        data[text_column], data[label_column], test_size=0.2, random_state=42
    )

    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)

    models = {
        'Naive Bayes': MultinomialNB(),
        'Logistic Regression': LogisticRegression(max_iter=1000),
        'SVM': LinearSVC(max_iter=1000)
    }

    results = {}
    for name, model in models.items():
        model.fit(X_train_tfidf, y_train)
        y_pred = model.predict(X_test_tfidf)
        accuracy = accuracy_score(y_test, y_pred)
        results[name] = accuracy
        print(f'{task_name} - {name} Accuracy: {accuracy:.4f}')

    return results, vectorizer, models

def plot_results(results_dict):
    fig, ax = plt.subplots(figsize=(10, 6))
    for dataset, accuracies in results_dict.items():
        ax.plot(list(accuracies.keys()), list(accuracies.values()), marker='o', label=dataset)
    ax.set_title('So sánh Độ chính xác của các Mô hình trên các Tập dữ liệu')
    ax.set_xlabel('Mô hình')
    ax.set_ylabel('Độ chính xác')
    ax.legend()
    plt.grid(True)
    plt.savefig(os.path.join(MODEL_DIR, 'model_comparison.png'))
    plt.close()

def train_and_save_model(X_train, y_train, model_type, dataset_name, models_dir):
    """Train a model and save it to disk"""
    if model_type == "naive_bayes":
        model = MultinomialNB()
    elif model_type == "logistic_regression":
        model = LogisticRegression(max_iter=1000)
    else:  # svm
        model = LinearSVC(max_iter=1000)
    
    model.fit(X_train, y_train)
    
    # Save model using joblib
    model_name = f"{dataset_name}_{model_type}.pkl"
    model_path = os.path.join(models_dir, model_name)
    joblib.dump(model, model_path)
    
    return model

def train_models(dataset_name, models_dir):
    """Train and save models for a specific dataset"""
    # Load and preprocess data
    X_train, y_train = load_and_preprocess_data(dataset_name)
    
    # Create and fit vectorizer
    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
    X_train_vec = vectorizer.fit_transform(X_train)
    
    # Save vectorizer using joblib
    vectorizer_path = os.path.join(models_dir, f"{dataset_name}_vectorizer.pkl")
    joblib.dump(vectorizer, vectorizer_path)
    
    # Train and save models
    models = {}
    for model_type in ["naive_bayes", "logistic_regression", "svm"]:
        model = train_and_save_model(X_train_vec, y_train, model_type, dataset_name, models_dir)
        models[model_type] = model
    
    return models, vectorizer

def main():
    # Tạo thư mục lưu mô hình
    global MODEL_DIR
    MODEL_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "server", "models")
    os.makedirs(MODEL_DIR, exist_ok=True)
    
    # Xóa các file mô hình cũ
    for file in os.listdir(MODEL_DIR):
        if file.endswith('.pkl') or file == 'model_comparison.png':
            try:
                os.remove(os.path.join(MODEL_DIR, file))
                print(f"Deleted old file: {file}")
            except Exception as e:
                print(f"Error deleting file {file}: {str(e)}")

    # Tải dữ liệu từ Hugging Face
    print("Loading IMDB dataset...")
    imdb_df = load_dataset_from_hf('imdb')
    imdb_results, imdb_vectorizer, imdb_models = preprocess_and_train(imdb_df, 'text', 'label', 'IMDB Reviews')

    print("\nLoading AG News dataset...")
    ag_news_df = load_dataset_from_hf('ag_news')
    ag_news_results, ag_news_vectorizer, ag_news_models = preprocess_and_train(ag_news_df, 'text', 'label', 'AG News')

    # print("\nLoading Twitter dataset...")
    # twitter_df = load_dataset_from_hf('sentiment140', split='train[:50000]')
    # twitter_df['label'] = twitter_df['sentiment'].map({0: 0, 4: 1})
    # twitter_results, twitter_vectorizer, twitter_models = preprocess_and_train(twitter_df, 'text', 'label', 'Twitter Sentiment')

    print("\nLoading Twitter dataset...")
    twitter_df = load_dataset_from_hf('sentiment140', split='train')  # Loại bỏ giới hạn 50000
    twitter_df['label'] = twitter_df['sentiment'].map({0: 0, 4: 1})
    # Kiểm tra nhãn
    print(f"Twitter Sentiment label counts:\n{twitter_df['label'].value_counts()}")
    twitter_results, twitter_vectorizer, twitter_models = preprocess_and_train(twitter_df, 'text', 'label', 'Twitter Sentiment')

    print("\nLoading SMS dataset...")
    sms_df = load_dataset_from_hf('sms_spam')
    sms_results, sms_vectorizer, sms_models = preprocess_and_train(sms_df, 'sms', 'label', 'SMS Spam')

    print("\nLoading BBC News dataset...")
    bbc_df = load_dataset_from_hf('ag_news')
    bbc_df['label'] = bbc_df['label'].factorize()[0]
    bbc_results, bbc_vectorizer, bbc_models = preprocess_and_train(bbc_df, 'text', 'label', 'BBC News')

    print("\nLoading Yelp dataset...")
    yelp_df = load_dataset_from_hf('yelp_review_full', split='train[:10000]')
    yelp_results, yelp_vectorizer, yelp_models = preprocess_and_train(yelp_df, 'text', 'label', 'Yelp Reviews')

    # Lưu mô hình và vectorizer vào thư mục models
    def save_models(models, vectorizer, name):
        joblib.dump(vectorizer, os.path.join(MODEL_DIR, f'{name}_vectorizer.pkl'))
        for model_name, model in models.items():
            model_name = model_name.replace(" ", "_")  # Replace spaces with underscores
            joblib.dump(model, os.path.join(MODEL_DIR, f'{name}_{model_name}.pkl'))
        print(f"Saved models and vectorizer for {name}")

    save_models(imdb_models, imdb_vectorizer, 'IMDB_Reviews')
    save_models(ag_news_models, ag_news_vectorizer, 'AG_News')
    save_models(twitter_models, twitter_vectorizer, 'Twitter_Sentiment')
    save_models(sms_models, sms_vectorizer, 'SMS_Spam')
    save_models(bbc_models, bbc_vectorizer, 'BBC_News')
    save_models(yelp_models, yelp_vectorizer, 'Yelp_Reviews')

    # So sánh kết quả
    results_dict = {
        'IMDB Reviews': imdb_results,
        'AG News': ag_news_results,
        'Twitter Sentiment': twitter_results,
        'SMS Spam': sms_results,
        'BBC News': bbc_results,
        'Yelp Reviews': yelp_results
    }

    for dataset, accuracies in results_dict.items():
        print(f'\n{dataset}:')
        for model, acc in accuracies.items():
            print(f'  {model}: {acc:.4f}')

    plot_results(results_dict)



def test_model():
    """Test the model with a sample input"""
    # Sample input
    test_text = "i love vietnam"
    print(f"\nTesting model with input: '{test_text}'")

    try:
        # Load the vectorizer and model
        dataset_name = "IMDB_Reviews"  # Using sentiment analysis model
        model_type = "SVM"  # Using SVM model
        
        vectorizer = joblib.load(os.path.join(MODEL_DIR, f"{dataset_name}_vectorizer.pkl"))
        model = joblib.load(os.path.join(MODEL_DIR, f"{dataset_name}_{model_type}.pkl"))
        
        # Transform the input text
        X = vectorizer.transform([test_text])
        
        # Make prediction
        prediction = model.predict(X)[0]
        sentiment = "Positive" if prediction == 1 else "Negative"
        
        print(f"Prediction: {sentiment} (raw value: {prediction})")
        print(f"Model used: {dataset_name} - {model_type}")
        
    except Exception as e:
        print(f"Error during testing: {str(e)}")

if __name__ == "__main__":
    main()
    # Run test after training
    test_model()

# import shutil

# # Nén thư mục models thành một file zip
# shutil.make_archive("models", 'zip', "models")

# # Tải về từ Colab
# from google.colab import files
# files.download("models.zip")

# import joblib
# import os

# # Load the models and vectorizers
# MODEL_DIR = "models"  # Assuming your models are saved in the 'models' directory

# def load_model_and_vectorizer(dataset_name, model_name):
#     vectorizer = joblib.load(os.path.join(MODEL_DIR, f'{dataset_name}_vectorizer.pkl'))
#     model = joblib.load(os.path.join(MODEL_DIR, f'{dataset_name}_{model_name}.pkl'))
#     return model, vectorizer

# # Choose a dataset and model for testing
# dataset_name = 'IMDB_Reviews'  # Change to your desired dataset
# model_name = 'Naive Bayes'  # Change to your desired model

# model, vectorizer = load_model_and_vectorizer(dataset_name, model_name)

# # Test cases
# test_cases = [
#     "This movie was amazing! I loved it.",  # Positive sentiment
#     "The acting was terrible and the plot was boring.",  # Negative sentiment
#     "It was an okay movie, nothing special.",  # Neutral sentiment
#     "I'm not sure how I feel about this film.",  # Ambiguous sentiment
#     "The special effects were great, but the story was weak.",  # Mixed sentiment
#     "This product is a piece of garbage! Don't waste your money.", # Negative for product review
#     "The food was delicious and the service was excellent!", # Positive for restaurant review
#     "This new phone is really cool and easy to use.", # Positive for product review
# ]

# # Predict and print results
# for text in test_cases:
#     # Preprocess the input text
#     text_tfidf = vectorizer.transform([text])

#     # Make prediction
#     prediction = model.predict(text_tfidf)[0]

#     # Print results
#     print(f"Text: {text}")
#     if dataset_name == 'IMDB_Reviews':
#         print(f"Predicted Sentiment: {'Positive' if prediction == 1 else 'Negative'}")
#     elif dataset_name == 'AG_News':
#         print(f"Predicted Class: {prediction}") # You'll need to interpret the class labels
#     # Add similar output for other datasets
#     print("-" * 20)

# # Đoạn mã này giả định rằng bạn đã chạy đoạn mã trước đó trong cùng một phiên Colab
# # và các biến `model`, `vectorizer`, `dataset_name` đã được tải và tồn tại.

# # Input mới
# new_input = "i love vietnam"

# # 1. Tiền xử lý input mới bằng vectorizer đã tải
# #    Lưu ý: vectorizer.transform() yêu cầu đầu vào là một iterable (ví dụ: list)
# new_input_tfidf = vectorizer.transform([new_input])

# # 2. Dự đoán bằng mô hình đã tải
# #    model.predict() trả về một mảng, lấy phần tử đầu tiên [0] cho dự đoán của input đơn lẻ này
# new_prediction = model.predict(new_input_tfidf)[0]

# # 3. In kết quả (sử dụng lại logic kiểm tra dataset_name từ đoạn mã trước)
# print(f"Input Text: {new_input}")
# if dataset_name == 'IMDB_Reviews':
#   predicted_sentiment = 'Positive' if new_prediction == 1 else 'Negative'
#   print(f"Predicted Sentiment: {predicted_sentiment}")
# elif dataset_name == 'AG_News':
#    # Logic cho AG_News nếu cần
#    print(f"Predicted Class: {new_prediction}")
# # Thêm các nhánh elif cho các dataset khác nếu có
# print("-" * 20)

# # Phân tích kết quả có thể xảy ra:
# # Mặc dù "love" là một từ tích cực mạnh, từ "vietnam" không có khả năng xuất hiện
# # thường xuyên hoặc không mang ý nghĩa cảm xúc cụ thể trong tập dữ liệu đánh giá phim IMDB.
# # Do đó, mô hình có thể dự đoán là "Negative" hoặc "Positive" tùy thuộc vào trọng số TF-IDF
# # của từ "love" và các từ khác (hoặc thiếu các từ khác) dựa trên những gì nó đã học từ đánh giá phim.
# # Kết quả này một lần nữa nhấn mạnh vấn đề "Không khớp miền" (Domain Mismatch).